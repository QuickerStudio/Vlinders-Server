# Vlinders-Server å·¥å…·æ‰§è¡Œå¼•æ“

**ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2026-02-28
**æ–‡æ¡£ç±»å‹**: æŠ€æœ¯è®¾è®¡

---

## ğŸ“‹ æ–‡æ¡£æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†æè¿° Vlinders-Server çš„å·¥å…·æ‰§è¡Œå¼•æ“è®¾è®¡ï¼ŒåŒ…æ‹¬å·¥å…·å®šä¹‰ã€æ²™ç®±æ‰§è¡Œã€å†…ç½®å·¥å…·ã€è‡ªå®šä¹‰å·¥å…·æ’ä»¶ç³»ç»Ÿã€å®‰å…¨æœºåˆ¶ç­‰ã€‚

---

## ğŸ¯ å·¥å…·ç³»ç»Ÿæ¦‚è¿°

### æ ¸å¿ƒå®šä½

> **å®‰å…¨ã€é«˜æ•ˆã€å¯æ‰©å±•çš„å·¥å…·æ‰§è¡Œå¼•æ“**
>
> å·¥å…·æ‰§è¡Œå¼•æ“æ˜¯ Agent ä¸å¤–éƒ¨ä¸–ç•Œäº¤äº’çš„æ¡¥æ¢ï¼Œè´Ÿè´£å®‰å…¨åœ°æ‰§è¡Œå„ç§å·¥å…·è°ƒç”¨ã€‚

### è®¾è®¡ç›®æ ‡

1. **å®‰å…¨æ€§** - æ²™ç®±éš”ç¦»ï¼Œé˜²æ­¢æ¶æ„ä»£ç æ‰§è¡Œ
2. **é«˜æ€§èƒ½** - æ”¯æŒå¹¶è¡Œæ‰§è¡Œï¼Œæœ€å°åŒ–å»¶è¿Ÿ
3. **å¯æ‰©å±•** - æ’ä»¶åŒ–è®¾è®¡ï¼Œæ˜“äºæ·»åŠ æ–°å·¥å…·
4. **å¯è§‚æµ‹** - å®Œæ•´çš„æ—¥å¿—å’Œç›‘æ§
5. **å®¹é”™æ€§** - ä¼˜é›…å¤„ç†å·¥å…·æ‰§è¡Œå¤±è´¥

### æ ¸å¿ƒç‰¹æ€§

- ğŸ”’ **Docker æ²™ç®±éš”ç¦»** - æ¯ä¸ªå·¥å…·åœ¨ç‹¬ç«‹å®¹å™¨ä¸­æ‰§è¡Œ
- âš¡ **å¹¶è¡Œæ‰§è¡Œ** - æ”¯æŒå¤šä¸ªå·¥å…·åŒæ—¶æ‰§è¡Œ
- ğŸ”Œ **æ’ä»¶ç³»ç»Ÿ** - åŠ¨æ€åŠ è½½è‡ªå®šä¹‰å·¥å…·
- ğŸ“Š **æ‰§è¡Œè¿½è¸ª** - è®°å½•æ‰€æœ‰å·¥å…·è°ƒç”¨å’Œç»“æœ
- â±ï¸ **è¶…æ—¶æ§åˆ¶** - é˜²æ­¢å·¥å…·æ‰§è¡Œæ—¶é—´è¿‡é•¿
- ğŸ’¾ **ç»“æœç¼“å­˜** - ç›¸åŒå‚æ•°çš„å·¥å…·è°ƒç”¨å¤ç”¨ç»“æœ

---

## ğŸ—ï¸ å·¥å…·æ‰§è¡Œå™¨æ¶æ„

### æ•´ä½“æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Tool Executor                            â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              Tool Registry                            â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚ â”‚
â”‚  â”‚  â”‚ Built-in â”‚  â”‚  Custom  â”‚  â”‚  Plugin  â”‚           â”‚ â”‚
â”‚  â”‚  â”‚  Tools   â”‚  â”‚  Tools   â”‚  â”‚  Loader  â”‚           â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                           â†“                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚           Execution Coordinator                       â”‚ â”‚
â”‚  â”‚  - å‚æ•°éªŒè¯                                           â”‚ â”‚
â”‚  â”‚  - æƒé™æ£€æŸ¥                                           â”‚ â”‚
â”‚  â”‚  - å¹¶è¡Œè°ƒåº¦                                           â”‚ â”‚
â”‚  â”‚  - ç»“æœèšåˆ                                           â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â†“              â†“              â†“                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚ Sandbox  â”‚  â”‚ Sandbox  â”‚  â”‚ Sandbox  â”‚                 â”‚
â”‚  â”‚ Worker 1 â”‚  â”‚ Worker 2 â”‚  â”‚ Worker N â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚         â†“              â†“              â†“                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              Docker Runtime                           â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚ â”‚
â”‚  â”‚  â”‚Container â”‚  â”‚Container â”‚  â”‚Container â”‚           â”‚ â”‚
â”‚  â”‚  â”‚    1     â”‚  â”‚    2     â”‚  â”‚    N     â”‚           â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ ¸å¿ƒç»„ä»¶

#### 1. Tool Registryï¼ˆå·¥å…·æ³¨å†Œè¡¨ï¼‰

**èŒè´£**: ç®¡ç†æ‰€æœ‰å¯ç”¨å·¥å…·

```python
from typing import Dict, List, Optional, Type
from dataclasses import dataclass
from enum import Enum

class ToolCategory(Enum):
    """å·¥å…·ç±»åˆ«"""
    CODE_ANALYSIS = "code_analysis"
    FILE_OPERATION = "file_operation"
    WEB_SEARCH = "web_search"
    SYSTEM = "system"
    CUSTOM = "custom"

@dataclass
class ToolDefinition:
    """å·¥å…·å®šä¹‰"""
    name: str
    description: str
    category: ToolCategory
    parameters: Dict[str, Any]
    required_permissions: List[str]
    timeout: int = 30
    cacheable: bool = True

    def validate_arguments(self, arguments: Dict[str, Any]) -> bool:
        """éªŒè¯å‚æ•°"""
        # æ£€æŸ¥å¿…éœ€å‚æ•°
        # éªŒè¯å‚æ•°ç±»å‹
        # éªŒè¯å‚æ•°èŒƒå›´
        pass

class ToolRegistry:
    """å·¥å…·æ³¨å†Œè¡¨"""

    def __init__(self):
        self.tools: Dict[str, ToolDefinition] = {}
        self.tool_instances: Dict[str, Tool] = {}
        self._register_builtin_tools()

    def register(self, tool: Tool):
        """æ³¨å†Œå·¥å…·"""
        if tool.name in self.tools:
            raise ValueError(f"Tool {tool.name} already registered")

        self.tools[tool.name] = tool.definition
        self.tool_instances[tool.name] = tool

        logger.info(f"Registered tool: {tool.name}")

    def unregister(self, tool_name: str):
        """æ³¨é”€å·¥å…·"""
        if tool_name not in self.tools:
            raise ValueError(f"Tool {tool_name} not found")

        del self.tools[tool_name]
        del self.tool_instances[tool_name]

        logger.info(f"Unregistered tool: {tool_name}")

    def get(self, tool_name: str) -> Optional[Tool]:
        """è·å–å·¥å…·å®ä¾‹"""
        return self.tool_instances.get(tool_name)

    def list_tools(
        self,
        category: Optional[ToolCategory] = None
    ) -> List[ToolDefinition]:
        """åˆ—å‡ºæ‰€æœ‰å·¥å…·"""
        tools = list(self.tools.values())

        if category:
            tools = [t for t in tools if t.category == category]

        return tools

    def _register_builtin_tools(self):
        """æ³¨å†Œå†…ç½®å·¥å…·"""
        from .builtin import (
            SearchCodeTool,
            SemanticSearchTool,
            ReadFileTool,
            AnalyzeCodeTool,
            WebSearchTool
        )

        for tool_class in [
            SearchCodeTool,
            SemanticSearchTool,
            ReadFileTool,
            AnalyzeCodeTool,
            WebSearchTool
        ]:
            self.register(tool_class())
```

#### 2. Execution Coordinatorï¼ˆæ‰§è¡Œåè°ƒå™¨ï¼‰

**èŒè´£**: åè°ƒå·¥å…·æ‰§è¡Œæµç¨‹

```python
import asyncio
from typing import List, Dict, Any
from dataclasses import dataclass

@dataclass
class ToolCall:
    """å·¥å…·è°ƒç”¨"""
    id: str
    tool_name: str
    arguments: Dict[str, Any]

@dataclass
class ToolResult:
    """å·¥å…·æ‰§è¡Œç»“æœ"""
    call_id: str
    tool_name: str
    success: bool
    result: Any
    error: Optional[str] = None
    duration_ms: int = 0
    cached: bool = False

class ExecutionCoordinator:
    """æ‰§è¡Œåè°ƒå™¨"""

    def __init__(
        self,
        registry: ToolRegistry,
        sandbox: Sandbox,
        cache: Cache,
        max_parallel: int = 10
    ):
        self.registry = registry
        self.sandbox = sandbox
        self.cache = cache
        self.semaphore = asyncio.Semaphore(max_parallel)

    async def execute_batch(
        self,
        tool_calls: List[ToolCall],
        context: ExecutionContext
    ) -> List[ToolResult]:
        """å¹¶è¡Œæ‰§è¡Œå¤šä¸ªå·¥å…·"""
        tasks = [
            self._execute_single(call, context)
            for call in tool_calls
        ]

        results = await asyncio.gather(*tasks, return_exceptions=True)

        # å¤„ç†å¼‚å¸¸
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                processed_results.append(ToolResult(
                    call_id=tool_calls[i].id,
                    tool_name=tool_calls[i].tool_name,
                    success=False,
                    result=None,
                    error=str(result)
                ))
            else:
                processed_results.append(result)

        return processed_results

    async def _execute_single(
        self,
        call: ToolCall,
        context: ExecutionContext
    ) -> ToolResult:
        """æ‰§è¡Œå•ä¸ªå·¥å…·"""
        start_time = time.time()

        async with self.semaphore:
            # 1. è·å–å·¥å…·
            tool = self.registry.get(call.tool_name)
            if not tool:
                return ToolResult(
                    call_id=call.id,
                    tool_name=call.tool_name,
                    success=False,
                    result=None,
                    error=f"Tool {call.tool_name} not found"
                )

            # 2. éªŒè¯å‚æ•°
            if not tool.definition.validate_arguments(call.arguments):
                return ToolResult(
                    call_id=call.id,
                    tool_name=call.tool_name,
                    success=False,
                    result=None,
                    error="Invalid arguments"
                )

            # 3. æ£€æŸ¥æƒé™
            if not self._check_permissions(tool, context):
                return ToolResult(
                    call_id=call.id,
                    tool_name=call.tool_name,
                    success=False,
                    result=None,
                    error="Permission denied"
                )

            # 4. æ£€æŸ¥ç¼“å­˜
            if tool.definition.cacheable:
                cache_key = self._get_cache_key(call)
                cached_result = await self.cache.get(cache_key)
                if cached_result:
                    return ToolResult(
                        call_id=call.id,
                        tool_name=call.tool_name,
                        success=True,
                        result=cached_result,
                        cached=True,
                        duration_ms=int((time.time() - start_time) * 1000)
                    )

            # 5. åœ¨æ²™ç®±ä¸­æ‰§è¡Œ
            try:
                result = await self.sandbox.execute(
                    tool=tool,
                    arguments=call.arguments,
                    context=context,
                    timeout=tool.definition.timeout
                )

                # 6. ç¼“å­˜ç»“æœ
                if tool.definition.cacheable:
                    await self.cache.set(
                        cache_key,
                        result,
                        ttl=300  # 5 åˆ†é’Ÿ
                    )

                duration_ms = int((time.time() - start_time) * 1000)

                return ToolResult(
                    call_id=call.id,
                    tool_name=call.tool_name,
                    success=True,
                    result=result,
                    duration_ms=duration_ms
                )

            except Exception as e:
                logger.error(f"Tool execution failed: {e}", exc_info=True)
                return ToolResult(
                    call_id=call.id,
                    tool_name=call.tool_name,
                    success=False,
                    result=None,
                    error=str(e),
                    duration_ms=int((time.time() - start_time) * 1000)
                )

    def _check_permissions(
        self,
        tool: Tool,
        context: ExecutionContext
    ) -> bool:
        """æ£€æŸ¥æƒé™"""
        required = tool.definition.required_permissions
        granted = context.permissions

        return all(perm in granted for perm in required)

    def _get_cache_key(self, call: ToolCall) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        import hashlib
        import json

        args_str = json.dumps(call.arguments, sort_keys=True)
        args_hash = hashlib.sha256(args_str.encode()).hexdigest()

        return f"tool:{call.tool_name}:{args_hash}"
```

#### 3. Sandbox Workerï¼ˆæ²™ç®±å·¥ä½œå™¨ï¼‰

**èŒè´£**: åœ¨éš”ç¦»ç¯å¢ƒä¸­æ‰§è¡Œå·¥å…·

```python
import docker
from typing import Any, Dict

class Sandbox:
    """æ²™ç®±è¿è¡Œæ—¶"""

    def __init__(self):
        self.client = docker.from_env()
        self.image = "vlinders/tool-sandbox:latest"
        self._ensure_image()

    async def execute(
        self,
        tool: Tool,
        arguments: Dict[str, Any],
        context: ExecutionContext,
        timeout: int = 30
    ) -> Any:
        """åœ¨æ²™ç®±ä¸­æ‰§è¡Œå·¥å…·"""

        # 1. å‡†å¤‡æ‰§è¡Œç¯å¢ƒ
        env_vars = {
            "TOOL_NAME": tool.name,
            "WORKSPACE": context.workspace,
            "USER_ID": context.user_id
        }

        # 2. åˆ›å»ºå®¹å™¨
        container = self.client.containers.run(
            image=self.image,
            command=self._build_command(tool, arguments),
            environment=env_vars,
            volumes={
                context.workspace: {
                    "bind": "/workspace",
                    "mode": "ro"  # åªè¯»
                }
            },
            network_mode="none",  # ç¦ç”¨ç½‘ç»œï¼ˆé™¤éå·¥å…·éœ€è¦ï¼‰
            mem_limit="512m",  # å†…å­˜é™åˆ¶
            cpu_quota=50000,  # CPU é™åˆ¶ï¼ˆ50%ï¼‰
            detach=True,
            remove=True
        )

        try:
            # 3. ç­‰å¾…æ‰§è¡Œå®Œæˆ
            result = container.wait(timeout=timeout)

            # 4. è·å–è¾“å‡º
            logs = container.logs().decode("utf-8")

            # 5. è§£æç»“æœ
            if result["StatusCode"] == 0:
                return self._parse_output(logs)
            else:
                raise RuntimeError(f"Tool execution failed: {logs}")

        except docker.errors.ContainerError as e:
            raise RuntimeError(f"Container error: {e}")

        except Exception as e:
            # è¶…æ—¶æˆ–å…¶ä»–é”™è¯¯ï¼Œå¼ºåˆ¶åœæ­¢å®¹å™¨
            try:
                container.stop(timeout=1)
            except:
                pass
            raise

    def _ensure_image(self):
        """ç¡®ä¿æ²™ç®±é•œåƒå­˜åœ¨"""
        try:
            self.client.images.get(self.image)
        except docker.errors.ImageNotFound:
            logger.info(f"Pulling sandbox image: {self.image}")
            self.client.images.pull(self.image)

    def _build_command(
        self,
        tool: Tool,
        arguments: Dict[str, Any]
    ) -> List[str]:
        """æ„å»ºæ‰§è¡Œå‘½ä»¤"""
        import json

        args_json = json.dumps(arguments)

        return [
            "python",
            "/sandbox/executor.py",
            "--tool", tool.name,
            "--args", args_json
        ]

    def _parse_output(self, logs: str) -> Any:
        """è§£æå·¥å…·è¾“å‡º"""
        import json

        # æŸ¥æ‰¾ JSON è¾“å‡º
        for line in logs.split("\n"):
            if line.startswith("RESULT:"):
                result_json = line[7:].strip()
                return json.loads(result_json)

        raise ValueError("No valid result found in output")
```

---

## ğŸ”§ å†…ç½®å·¥å…·è¯¦è§£

### 1. search_code - ä»£ç æœç´¢

**åŠŸèƒ½**: åœ¨ä»£ç åº“ä¸­æœç´¢æ–‡æœ¬æˆ–æ­£åˆ™è¡¨è¾¾å¼

**å®šä¹‰**:
```python
class SearchCodeTool(Tool):
    """ä»£ç æœç´¢å·¥å…·"""

    def __init__(self):
        self.definition = ToolDefinition(
            name="search_code",
            description="Search for text or regex patterns in codebase",
            category=ToolCategory.CODE_ANALYSIS,
            parameters={
                "pattern": {
                    "type": "string",
                    "description": "Search pattern (text or regex)",
                    "required": True
                },
                "path": {
                    "type": "string",
                    "description": "Path to search in (default: workspace root)",
                    "required": False
                },
                "file_pattern": {
                    "type": "string",
                    "description": "File pattern to filter (e.g., '*.py')",
                    "required": False
                },
                "case_sensitive": {
                    "type": "boolean",
                    "description": "Case sensitive search",
                    "required": False,
                    "default": False
                },
                "max_results": {
                    "type": "integer",
                    "description": "Maximum number of results",
                    "required": False,
                    "default": 100
                }
            },
            required_permissions=["read:code"],
            timeout=30,
            cacheable=True
        )

    async def execute(
        self,
        arguments: Dict[str, Any],
        context: ExecutionContext
    ) -> Dict[str, Any]:
        """æ‰§è¡Œä»£ç æœç´¢"""
        pattern = arguments["pattern"]
        path = arguments.get("path", context.workspace)
        file_pattern = arguments.get("file_pattern", "*")
        case_sensitive = arguments.get("case_sensitive", False)
        max_results = arguments.get("max_results", 100)

        # ä½¿ç”¨ ripgrep è¿›è¡Œæœç´¢
        import subprocess

        cmd = ["rg", pattern]

        if not case_sensitive:
            cmd.append("-i")

        cmd.extend([
            "--json",
            "--max-count", str(max_results),
            "--glob", file_pattern,
            path
        ])

        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=30
        )

        # è§£æç»“æœ
        matches = []
        for line in result.stdout.split("\n"):
            if not line:
                continue

            try:
                data = json.loads(line)
                if data["type"] == "match":
                    matches.append({
                        "file": data["data"]["path"]["text"],
                        "line": data["data"]["line_number"],
                        "content": data["data"]["lines"]["text"],
                        "match": data["data"]["submatches"]
                    })
            except:
                continue

        return {
            "matches": matches[:max_results],
            "total": len(matches),
            "truncated": len(matches) > max_results
        }
```

### 2. semantic_search - è¯­ä¹‰æœç´¢

**åŠŸèƒ½**: ä½¿ç”¨å‘é‡ç›¸ä¼¼åº¦è¿›è¡Œè¯­ä¹‰æœç´¢

**å®šä¹‰**:
```python
class SemanticSearchTool(Tool):
    """è¯­ä¹‰æœç´¢å·¥å…·"""

    def __init__(self, qdrant_client: QdrantClient, embedding_service: EmbeddingService):
        self.qdrant = qdrant_client
        self.embeddings = embedding_service

        self.definition = ToolDefinition(
            name="semantic_search",
            description="Search code using semantic similarity",
            category=ToolCategory.CODE_ANALYSIS,
            parameters={
                "query": {
                    "type": "string",
                    "description": "Natural language query",
                    "required": True
                },
                "language": {
                    "type": "string",
                    "description": "Programming language filter",
                    "required": False
                },
                "limit": {
                    "type": "integer",
                    "description": "Maximum number of results",
                    "required": False,
                    "default": 10
                }
            },
            required_permissions=["read:code"],
            timeout=10,
            cacheable=True
        )

    async def execute(
        self,
        arguments: Dict[str, Any],
        context: ExecutionContext
    ) -> Dict[str, Any]:
        """æ‰§è¡Œè¯­ä¹‰æœç´¢"""
        query = arguments["query"]
        language = arguments.get("language")
        limit = arguments.get("limit", 10)

        # 1. ç”ŸæˆæŸ¥è¯¢å‘é‡
        query_vector = await self.embeddings.embed(query)

        # 2. æ„å»ºè¿‡æ»¤æ¡ä»¶
        filters = {
            "workspace": context.workspace
        }
        if language:
            filters["language"] = language

        # 3. å‘é‡æœç´¢
        results = await self.qdrant.search(
            collection_name="code_embeddings",
            query_vector=query_vector,
            query_filter=filters,
            limit=limit
        )

        # 4. æ ¼å¼åŒ–ç»“æœ
        matches = []
        for result in results:
            matches.append({
                "file": result.payload["file_path"],
                "code": result.payload["code"],
                "language": result.payload["language"],
                "symbols": result.payload.get("symbols", []),
                "score": result.score,
                "line_range": {
                    "start": result.payload["start_line"],
                    "end": result.payload["end_line"]
                }
            })

        return {
            "matches": matches,
            "total": len(matches)
        }
```

### 3. read_file - æ–‡ä»¶è¯»å–

**åŠŸèƒ½**: è¯»å–æ–‡ä»¶å†…å®¹

**å®šä¹‰**:
```python
class ReadFileTool(Tool):
    """æ–‡ä»¶è¯»å–å·¥å…·"""

    def __init__(self):
        self.definition = ToolDefinition(
            name="read_file",
            description="Read file contents",
            category=ToolCategory.FILE_OPERATION,
            parameters={
                "path": {
                    "type": "string",
                    "description": "File path (relative to workspace)",
                    "required": True
                },
                "start_line": {
                    "type": "integer",
                    "description": "Start line number (1-indexed)",
                    "required": False
                },
                "end_line": {
                    "type": "integer",
                    "description": "End line number (inclusive)",
                    "required": False
                },
                "encoding": {
                    "type": "string",
                    "description": "File encoding",
                    "required": False,
                    "default": "utf-8"
                }
            },
            required_permissions=["read:file"],
            timeout=10,
            cacheable=True
        )

    async def execute(
        self,
        arguments: Dict[str, Any],
        context: ExecutionContext
    ) -> Dict[str, Any]:
        """æ‰§è¡Œæ–‡ä»¶è¯»å–"""
        import os

        path = arguments["path"]
        start_line = arguments.get("start_line")
        end_line = arguments.get("end_line")
        encoding = arguments.get("encoding", "utf-8")

        # 1. æ„å»ºå®Œæ•´è·¯å¾„
        full_path = os.path.join(context.workspace, path)

        # 2. å®‰å…¨æ£€æŸ¥
        if not os.path.abspath(full_path).startswith(context.workspace):
            raise ValueError("Path outside workspace")

        if not os.path.exists(full_path):
            raise FileNotFoundError(f"File not found: {path}")

        # 3. è¯»å–æ–‡ä»¶
        try:
            with open(full_path, "r", encoding=encoding) as f:
                lines = f.readlines()

            # 4. æå–æŒ‡å®šè¡Œ
            if start_line is not None or end_line is not None:
                start = (start_line or 1) - 1
                end = end_line if end_line else len(lines)
                lines = lines[start:end]

            content = "".join(lines)

            return {
                "path": path,
                "content": content,
                "lines": len(lines),
                "size": len(content)
            }

        except UnicodeDecodeError:
            raise ValueError(f"Cannot decode file with encoding: {encoding}")
```

### 4. analyze_code - ä»£ç åˆ†æ

**åŠŸèƒ½**: ä½¿ç”¨ Tree-sitter åˆ†æä»£ç ç»“æ„

**å®šä¹‰**:
```python
class AnalyzeCodeTool(Tool):
    """ä»£ç åˆ†æå·¥å…·"""

    def __init__(self, code_analyzer: CodeAnalysisEngine):
        self.analyzer = code_analyzer

        self.definition = ToolDefinition(
            name="analyze_code",
            description="Analyze code structure using Tree-sitter",
            category=ToolCategory.CODE_ANALYSIS,
            parameters={
                "path": {
                    "type": "string",
                    "description": "File path to analyze",
                    "required": True
                },
                "analysis_type": {
                    "type": "string",
                    "description": "Type of analysis: symbols, dependencies, complexity",
                    "required": False,
                    "default": "symbols"
                }
            },
            required_permissions=["read:code"],
            timeout=30,
            cacheable=True
        )

    async def execute(
        self,
        arguments: Dict[str, Any],
        context: ExecutionContext
    ) -> Dict[str, Any]:
        """æ‰§è¡Œä»£ç åˆ†æ"""
        import os

        path = arguments["path"]
        analysis_type = arguments.get("analysis_type", "symbols")

        # 1. è¯»å–æ–‡ä»¶
        full_path = os.path.join(context.workspace, path)
        with open(full_path, "r") as f:
            code = f.read()

        # 2. æ£€æµ‹è¯­è¨€
        language = self._detect_language(path)

        # 3. è§£æä»£ç 
        tree = self.analyzer.parse_file(code, language)

        # 4. æ‰§è¡Œåˆ†æ
        if analysis_type == "symbols":
            symbols = self.analyzer.extract_symbols(tree)
            return {
                "path": path,
                "language": language,
                "symbols": [
                    {
                        "name": s.name,
                        "type": s.type,
                        "line": s.line,
                        "signature": s.signature
                    }
                    for s in symbols
                ]
            }

        elif analysis_type == "dependencies":
            deps = self.analyzer.analyze_dependencies(tree)
            return {
                "path": path,
                "language": language,
                "dependencies": [
                    {
                        "name": d.name,
                        "type": d.type,
                        "source": d.source
                    }
                    for d in deps
                ]
            }

        elif analysis_type == "complexity":
            complexity = self.analyzer.calculate_complexity(tree)
            return {
                "path": path,
                "language": language,
                "complexity": complexity
            }

        else:
            raise ValueError(f"Unknown analysis type: {analysis_type}")

    def _detect_language(self, path: str) -> str:
        """æ£€æµ‹ç¼–ç¨‹è¯­è¨€"""
        ext_map = {
            ".py": "python",
            ".js": "javascript",
            ".ts": "typescript",
            ".go": "go",
            ".rs": "rust",
            ".java": "java",
            ".cpp": "cpp",
            ".c": "c"
        }

        ext = os.path.splitext(path)[1]
        return ext_map.get(ext, "unknown")
```

### 5. web_search - Web æœç´¢

**åŠŸèƒ½**: æœç´¢äº’è”ç½‘å†…å®¹

**å®šä¹‰**:
```python
class WebSearchTool(Tool):
    """Web æœç´¢å·¥å…·"""

    def __init__(self, search_api_key: str):
        self.api_key = search_api_key

        self.definition = ToolDefinition(
            name="web_search",
            description="Search the web for information",
            category=ToolCategory.WEB_SEARCH,
            parameters={
                "query": {
                    "type": "string",
                    "description": "Search query",
                    "required": True
                },
                "num_results": {
                    "type": "integer",
                    "description": "Number of results",
                    "required": False,
                    "default": 5
                }
            },
            required_permissions=["web:search"],
            timeout=10,
            cacheable=True
        )

    async def execute(
        self,
        arguments: Dict[str, Any],
        context: ExecutionContext
    ) -> Dict[str, Any]:
        """æ‰§è¡Œ Web æœç´¢"""
        import aiohttp

        query = arguments["query"]
        num_results = arguments.get("num_results", 5)

        # ä½¿ç”¨ Google Custom Search API
        url = "https://www.googleapis.com/customsearch/v1"
        params = {
            "key": self.api_key,
            "cx": "your_search_engine_id",
            "q": query,
            "num": num_results
        }

        async with aiohttp.ClientSession() as session:
            async with session.get(url, params=params) as response:
                data = await response.json()

        # æ ¼å¼åŒ–ç»“æœ
        results = []
        for item in data.get("items", []):
            results.append({
                "title": item["title"],
                "url": item["link"],
                "snippet": item["snippet"]
            })

        return {
            "query": query,
            "results": results,
            "total": len(results)
        }
```

---

## ğŸ“‹ å·¥å…·å®šä¹‰è§„èŒƒ

### å·¥å…·æ¥å£

æ‰€æœ‰å·¥å…·å¿…é¡»å®ç°ä»¥ä¸‹æ¥å£ï¼š

```python
from abc import ABC, abstractmethod

class Tool(ABC):
    """å·¥å…·åŸºç±»"""

    def __init__(self):
        self.definition: ToolDefinition = None

    @abstractmethod
    async def execute(
        self,
        arguments: Dict[str, Any],
        context: ExecutionContext
    ) -> Any:
        """æ‰§è¡Œå·¥å…·"""
        pass

    def validate(self, arguments: Dict[str, Any]) -> bool:
        """éªŒè¯å‚æ•°ï¼ˆå¯é€‰é‡å†™ï¼‰"""
        return self.definition.validate_arguments(arguments)
```

### å‚æ•°ç±»å‹

æ”¯æŒçš„å‚æ•°ç±»å‹ï¼š

```python
SUPPORTED_TYPES = {
    "string": str,
    "integer": int,
    "number": float,
    "boolean": bool,
    "array": list,
    "object": dict
}
```

### ç¤ºä¾‹ï¼šè‡ªå®šä¹‰å·¥å…·

```python
class GitLogTool(Tool):
    """Git æ—¥å¿—å·¥å…·"""

    def __init__(self):
        self.definition = ToolDefinition(
            name="git_log",
            description="Get git commit history",
            category=ToolCategory.SYSTEM,
            parameters={
                "path": {
                    "type": "string",
                    "description": "Repository path",
                    "required": False
                },
                "limit": {
                    "type": "integer",
                    "description": "Number of commits",
                    "required": False,
                    "default": 10
                },
                "author": {
                    "type": "string",
                    "description": "Filter by author",
                    "required": False
                }
            },
            required_permissions=["read:git"],
            timeout=10,
            cacheable=True
        )

    async def execute(
        self,
        arguments: Dict[str, Any],
        context: ExecutionContext
    ) -> Dict[str, Any]:
        """æ‰§è¡Œ git log"""
        import subprocess

        path = arguments.get("path", context.workspace)
        limit = arguments.get("limit", 10)
        author = arguments.get("author")

        cmd = ["git", "-C", path, "log", f"-{limit}", "--pretty=format:%H|%an|%ae|%ad|%s"]

        if author:
            cmd.extend(["--author", author])

        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=10
        )

        if result.returncode != 0:
            raise RuntimeError(f"Git command failed: {result.stderr}")

        # è§£æè¾“å‡º
        commits = []
        for line in result.stdout.split("\n"):
            if not line:
                continue

            parts = line.split("|")
            commits.append({
                "hash": parts[0],
                "author": parts[1],
                "email": parts[2],
                "date": parts[3],
                "message": parts[4]
            })

        return {
            "commits": commits,
            "total": len(commits)
        }
```

---

## ğŸ³ æ²™ç®±æ‰§è¡Œè¯¦è§£

### Docker é•œåƒ

**Dockerfile**:
```dockerfile
FROM python:3.11-slim

# å®‰è£…å¿…è¦å·¥å…·
RUN apt-get update && apt-get install -y \
    ripgrep \
    git \
    && rm -rf /var/lib/apt/lists/*

# å®‰è£… Python ä¾èµ–
COPY requirements.txt /tmp/
RUN pip install --no-cache-dir -r /tmp/requirements.txt

# å¤åˆ¶æ‰§è¡Œå™¨
COPY executor.py /sandbox/executor.py

# åˆ›å»ºé root ç”¨æˆ·
RUN useradd -m -u 1000 sandbox
USER sandbox

WORKDIR /workspace

ENTRYPOINT ["python", "/sandbox/executor.py"]
```

### æ²™ç®±æ‰§è¡Œå™¨

**executor.py**:
```python
#!/usr/bin/env python3
"""
æ²™ç®±å·¥å…·æ‰§è¡Œå™¨

åœ¨éš”ç¦»ç¯å¢ƒä¸­æ‰§è¡Œå·¥å…·
"""

import sys
import json
import argparse
import traceback

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--tool", required=True)
    parser.add_argument("--args", required=True)
    args = parser.parse_args()

    try:
        # 1. è§£æå‚æ•°
        tool_name = args.tool
        arguments = json.loads(args.args)

        # 2. åŠ è½½å·¥å…·
        tool = load_tool(tool_name)

        # 3. æ‰§è¡Œå·¥å…·
        result = tool.execute(arguments)

        # 4. è¾“å‡ºç»“æœ
        print(f"RESULT:{json.dumps(result)}")
        sys.exit(0)

    except Exception as e:
        print(f"ERROR:{str(e)}", file=sys.stderr)
        traceback.print_exc(file=sys.stderr)
        sys.exit(1)

def load_tool(tool_name: str):
    """åŠ è½½å·¥å…·"""
    # åŠ¨æ€å¯¼å…¥å·¥å…·æ¨¡å—
    module = __import__(f"tools.{tool_name}", fromlist=["Tool"])
    return module.Tool()

if __name__ == "__main__":
    main()
```

### å®‰å…¨é…ç½®

**seccomp profile**:
```json
{
  "defaultAction": "SCMP_ACT_ERRNO",
  "architectures": ["SCMP_ARCH_X86_64"],
  "syscalls": [
    {
      "names": [
        "read", "write", "open", "close",
        "stat", "fstat", "lstat",
        "poll", "lseek", "mmap", "mprotect",
        "munmap", "brk", "rt_sigaction",
        "rt_sigprocmask", "rt_sigreturn",
        "ioctl", "pread64", "pwrite64",
        "readv", "writev", "access",
        "pipe", "select", "sched_yield",
        "mremap", "msync", "mincore",
        "madvise", "shmget", "shmat",
        "shmctl", "dup", "dup2",
        "pause", "nanosleep", "getitimer",
        "alarm", "setitimer", "getpid",
        "sendfile", "socket", "connect",
        "accept", "sendto", "recvfrom",
        "sendmsg", "recvmsg", "shutdown",
        "bind", "listen", "getsockname",
        "getpeername", "socketpair",
        "setsockopt", "getsockopt", "clone",
        "fork", "vfork", "execve",
        "exit", "wait4", "kill",
        "uname", "semget", "semop",
        "semctl", "shmdt", "msgget",
        "msgsnd", "msgrcv", "msgctl",
        "fcntl", "flock", "fsync",
        "fdatasync", "truncate", "ftruncate",
        "getdents", "getcwd", "chdir",
        "fchdir", "rename", "mkdir",
        "rmdir", "creat", "link",
        "unlink", "symlink", "readlink",
        "chmod", "fchmod", "chown",
        "fchown", "lchown", "umask",
        "gettimeofday", "getrlimit", "getrusage",
        "sysinfo", "times", "ptrace",
        "getuid", "syslog", "getgid",
        "setuid", "setgid", "geteuid",
        "getegid", "setpgid", "getppid",
        "getpgrp", "setsid", "setreuid",
        "setregid", "getgroups", "setgroups",
        "setresuid", "getresuid", "setresgid",
        "getresgid", "getpgid", "setfsuid",
        "setfsgid", "getsid", "capget",
        "capset", "rt_sigpending", "rt_sigtimedwait",
        "rt_sigqueueinfo", "rt_sigsuspend", "sigaltstack",
        "utime", "mknod", "uselib",
        "personality", "ustat", "statfs",
        "fstatfs", "sysfs", "getpriority",
        "setpriority", "sched_setparam", "sched_getparam",
        "sched_setscheduler", "sched_getscheduler", "sched_get_priority_max",
        "sched_get_priority_min", "sched_rr_get_interval", "mlock",
        "munlock", "mlockall", "munlockall",
        "vhangup", "modify_ldt", "pivot_root",
        "_sysctl", "prctl", "arch_prctl",
        "adjtimex", "setrlimit", "chroot",
        "sync", "acct", "settimeofday",
        "mount", "umount2", "swapon",
        "swapoff", "reboot", "sethostname",
        "setdomainname", "iopl", "ioperm",
        "create_module", "init_module", "delete_module",
        "get_kernel_syms", "query_module", "quotactl",
        "nfsservctl", "getpmsg", "putpmsg",
        "afs_syscall", "tuxcall", "security",
        "gettid", "readahead", "setxattr",
        "lsetxattr", "fsetxattr", "getxattr",
        "lgetxattr", "fgetxattr", "listxattr",
        "llistxattr", "flistxattr", "removexattr",
        "lremovexattr", "fremovexattr", "tkill",
        "time", "futex", "sched_setaffinity",
        "sched_getaffinity", "set_thread_area", "io_setup",
        "io_destroy", "io_getevents", "io_submit",
        "io_cancel", "get_thread_area", "lookup_dcookie",
        "epoll_create", "epoll_ctl_old", "epoll_wait_old",
        "remap_file_pages", "getdents64", "set_tid_address",
        "restart_syscall", "semtimedop", "fadvise64",
        "timer_create", "timer_settime", "timer_gettime",
        "timer_getoverrun", "timer_delete", "clock_settime",
        "clock_gettime", "clock_getres", "clock_nanosleep",
        "exit_group", "epoll_wait", "epoll_ctl",
        "tgkill", "utimes", "vserver",
        "mbind", "set_mempolicy", "get_mempolicy",
        "mq_open", "mq_unlink", "mq_timedsend",
        "mq_timedreceive", "mq_notify", "mq_getsetattr",
        "kexec_load", "waitid", "add_key",
        "request_key", "keyctl", "ioprio_set",
        "ioprio_get", "inotify_init", "inotify_add_watch",
        "inotify_rm_watch", "migrate_pages", "openat",
        "mkdirat", "mknodat", "fchownat",
        "futimesat", "newfstatat", "unlinkat",
        "renameat", "linkat", "symlinkat",
        "readlinkat", "fchmodat", "faccessat",
        "pselect6", "ppoll", "unshare",
        "set_robust_list", "get_robust_list", "splice",
        "tee", "sync_file_range", "vmsplice",
        "move_pages", "utimensat", "epoll_pwait",
        "signalfd", "timerfd_create", "eventfd",
        "fallocate", "timerfd_settime", "timerfd_gettime",
        "accept4", "signalfd4", "eventfd2",
        "epoll_create1", "dup3", "pipe2",
        "inotify_init1", "preadv", "pwritev",
        "rt_tgsigqueueinfo", "perf_event_open", "recvmmsg",
        "fanotify_init", "fanotify_mark", "prlimit64",
        "name_to_handle_at", "open_by_handle_at", "clock_adjtime",
        "syncfs", "sendmmsg", "setns",
        "getcpu", "process_vm_readv", "process_vm_writev",
        "kcmp", "finit_module", "sched_setattr",
        "sched_getattr", "renameat2", "seccomp",
        "getrandom", "memfd_create", "kexec_file_load",
        "bpf", "execveat", "userfaultfd",
        "membarrier", "mlock2", "copy_file_range",
        "preadv2", "pwritev2", "pkey_mprotect",
        "pkey_alloc", "pkey_free", "statx"
      ],
      "action": "SCMP_ACT_ALLOW"
    }
  ]
}
```

---

## âš¡ å¹¶è¡Œæ‰§è¡Œæœºåˆ¶

### æ‰§è¡Œæµç¨‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Parallel Execution Flow                    â”‚
â”‚                                                         â”‚
â”‚  1. æ¥æ”¶å·¥å…·è°ƒç”¨åˆ—è¡¨                                     â”‚
â”‚     [tool1, tool2, tool3, ...]                         â”‚
â”‚     â†“                                                   â”‚
â”‚  2. åˆ†æä¾èµ–å…³ç³»                                         â”‚
â”‚     - æ£€æµ‹æ•°æ®ä¾èµ–                                       â”‚
â”‚     - æ„å»ºæ‰§è¡Œå›¾                                         â”‚
â”‚     â†“                                                   â”‚
â”‚  3. åˆ†ç»„æ‰§è¡Œ                                             â”‚
â”‚     Group 1: [tool1, tool2]  (å¹¶è¡Œ)                    â”‚
â”‚     Group 2: [tool3]         (ä¾èµ– tool1)              â”‚
â”‚     Group 3: [tool4, tool5]  (å¹¶è¡Œ)                    â”‚
â”‚     â†“                                                   â”‚
â”‚  4. å¹¶å‘æ§åˆ¶                                             â”‚
â”‚     - Semaphore é™åˆ¶å¹¶å‘æ•°                              â”‚
â”‚     - èµ„æºåˆ†é…                                           â”‚
â”‚     â†“                                                   â”‚
â”‚  5. æ‰§è¡Œç›‘æ§                                             â”‚
â”‚     - è¶…æ—¶æ£€æµ‹                                           â”‚
â”‚     - é”™è¯¯å¤„ç†                                           â”‚
â”‚     â†“                                                   â”‚
â”‚  6. ç»“æœèšåˆ                                             â”‚
â”‚     - æ”¶é›†æ‰€æœ‰ç»“æœ                                       â”‚
â”‚     - å¤„ç†å¼‚å¸¸                                           â”‚
â”‚     â†“                                                   â”‚
â”‚  7. è¿”å›ç»“æœ                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ä¾èµ–åˆ†æ

```python
class DependencyAnalyzer:
    """å·¥å…·ä¾èµ–åˆ†æå™¨"""

    def analyze(
        self,
        tool_calls: List[ToolCall]
    ) -> List[List[ToolCall]]:
        """
        åˆ†æå·¥å…·è°ƒç”¨çš„ä¾èµ–å…³ç³»ï¼Œè¿”å›æ‰§è¡Œåˆ†ç»„

        è¿”å›: [[group1], [group2], ...]
        æ¯ä¸ª group å†…çš„å·¥å…·å¯ä»¥å¹¶è¡Œæ‰§è¡Œ
        """
        # 1. æ„å»ºä¾èµ–å›¾
        graph = self._build_dependency_graph(tool_calls)

        # 2. æ‹“æ‰‘æ’åº
        sorted_calls = self._topological_sort(graph)

        # 3. åˆ†ç»„
        groups = self._group_by_level(sorted_calls, graph)

        return groups

    def _build_dependency_graph(
        self,
        tool_calls: List[ToolCall]
    ) -> Dict[str, List[str]]:
        """æ„å»ºä¾èµ–å›¾"""
        graph = {call.id: [] for call in tool_calls}

        for call in tool_calls:
            # æ£€æŸ¥å‚æ•°ä¸­æ˜¯å¦å¼•ç”¨å…¶ä»–å·¥å…·çš„ç»“æœ
            for arg_value in call.arguments.values():
                if isinstance(arg_value, str) and arg_value.startswith("$"):
                    # å¼•ç”¨æ ¼å¼: $tool_call_id.field
                    ref_id = arg_value.split(".")[0][1:]
                    if ref_id in graph:
                        graph[call.id].append(ref_id)

        return graph

    def _topological_sort(
        self,
        graph: Dict[str, List[str]]
    ) -> List[str]:
        """æ‹“æ‰‘æ’åº"""
        from collections import deque

        # è®¡ç®—å…¥åº¦
        in_degree = {node: 0 for node in graph}
        for node in graph:
            for neighbor in graph[node]:
                in_degree[neighbor] += 1

        # BFS
        queue = deque([node for node in graph if in_degree[node] == 0])
        result = []

        while queue:
            node = queue.popleft()
            result.append(node)

            for neighbor in graph[node]:
                in_degree[neighbor] -= 1
                if in_degree[neighbor] == 0:
                    queue.append(neighbor)

        if len(result) != len(graph):
            raise ValueError("Circular dependency detected")

        return result

    def _group_by_level(
        self,
        sorted_calls: List[str],
        graph: Dict[str, List[str]]
    ) -> List[List[str]]:
        """æŒ‰å±‚çº§åˆ†ç»„"""
        levels = {}
        max_level = 0

        for call_id in sorted_calls:
            # è®¡ç®—å½“å‰èŠ‚ç‚¹çš„å±‚çº§
            deps = graph[call_id]
            if not deps:
                level = 0
            else:
                level = max(levels[dep] for dep in deps) + 1

            levels[call_id] = level
            max_level = max(max_level, level)

        # æŒ‰å±‚çº§åˆ†ç»„
        groups = [[] for _ in range(max_level + 1)]
        for call_id, level in levels.items():
            groups[level].append(call_id)

        return groups
```

### å¹¶å‘æ§åˆ¶

```python
class ConcurrencyController:
    """å¹¶å‘æ§åˆ¶å™¨"""

    def __init__(self, max_concurrent: int = 10):
        self.semaphore = asyncio.Semaphore(max_concurrent)
        self.active_tasks: Dict[str, asyncio.Task] = {}

    async def execute_group(
        self,
        tool_calls: List[ToolCall],
        executor: ExecutionCoordinator,
        context: ExecutionContext
    ) -> List[ToolResult]:
        """å¹¶è¡Œæ‰§è¡Œä¸€ç»„å·¥å…·"""
        async def execute_with_semaphore(call: ToolCall):
            async with self.semaphore:
                return await executor._execute_single(call, context)

        tasks = [
            execute_with_semaphore(call)
            for call in tool_calls
        ]

        # è®°å½•æ´»è·ƒä»»åŠ¡
        for i, task in enumerate(tasks):
            self.active_tasks[tool_calls[i].id] = task

        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # æ¸…ç†ä»»åŠ¡è®°å½•
        for call in tool_calls:
            self.active_tasks.pop(call.id, None)

        return results

    async def cancel_all(self):
        """å–æ¶ˆæ‰€æœ‰æ´»è·ƒä»»åŠ¡"""
        for task in self.active_tasks.values():
            task.cancel()

        await asyncio.gather(*self.active_tasks.values(), return_exceptions=True)
        self.active_tasks.clear()
```

---

## ğŸ”Œ è‡ªå®šä¹‰å·¥å…·æ’ä»¶ç³»ç»Ÿ

### æ’ä»¶åŠ è½½å™¨

```python
import importlib
import os
from pathlib import Path

class PluginLoader:
    """æ’ä»¶åŠ è½½å™¨"""

    def __init__(self, plugin_dir: str):
        self.plugin_dir = Path(plugin_dir)
        self.loaded_plugins: Dict[str, Tool] = {}

    def load_all(self) -> List[Tool]:
        """åŠ è½½æ‰€æœ‰æ’ä»¶"""
        if not self.plugin_dir.exists():
            logger.warning(f"Plugin directory not found: {self.plugin_dir}")
            return []

        tools = []

        for plugin_file in self.plugin_dir.glob("*.py"):
            if plugin_file.name.startswith("_"):
                continue

            try:
                tool = self.load_plugin(plugin_file)
                tools.append(tool)
                logger.info(f"Loaded plugin: {tool.name}")
            except Exception as e:
                logger.error(f"Failed to load plugin {plugin_file}: {e}")

        return tools

    def load_plugin(self, plugin_file: Path) -> Tool:
        """åŠ è½½å•ä¸ªæ’ä»¶"""
        # 1. åŠ¨æ€å¯¼å…¥æ¨¡å—
        module_name = plugin_file.stem
        spec = importlib.util.spec_from_file_location(module_name, plugin_file)
        module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(module)

        # 2. æŸ¥æ‰¾ Tool ç±»
        tool_class = None
        for name in dir(module):
            obj = getattr(module, name)
            if isinstance(obj, type) and issubclass(obj, Tool) and obj != Tool:
                tool_class = obj
                break

        if not tool_class:
            raise ValueError(f"No Tool class found in {plugin_file}")

        # 3. å®ä¾‹åŒ–å·¥å…·
        tool = tool_class()

        # 4. éªŒè¯å·¥å…·å®šä¹‰
        self._validate_tool(tool)

        self.loaded_plugins[tool.name] = tool

        return tool

    def _validate_tool(self, tool: Tool):
        """éªŒè¯å·¥å…·å®šä¹‰"""
        if not tool.definition:
            raise ValueError("Tool definition is required")

        if not tool.definition.name:
            raise ValueError("Tool name is required")

        if not tool.definition.description:
            raise ValueError("Tool description is required")

        if not tool.definition.parameters:
            raise ValueError("Tool parameters are required")

    def reload_plugin(self, tool_name: str):
        """é‡æ–°åŠ è½½æ’ä»¶"""
        if tool_name not in self.loaded_plugins:
            raise ValueError(f"Plugin {tool_name} not loaded")

        # æŸ¥æ‰¾æ’ä»¶æ–‡ä»¶
        plugin_file = self.plugin_dir / f"{tool_name}.py"
        if not plugin_file.exists():
            raise FileNotFoundError(f"Plugin file not found: {plugin_file}")

        # é‡æ–°åŠ è½½
        tool = self.load_plugin(plugin_file)

        return tool

    def unload_plugin(self, tool_name: str):
        """å¸è½½æ’ä»¶"""
        if tool_name in self.loaded_plugins:
            del self.loaded_plugins[tool_name]
            logger.info(f"Unloaded plugin: {tool_name}")
```

### æ’ä»¶ç¤ºä¾‹

**plugins/docker_stats.py**:
```python
"""
Docker ç»Ÿè®¡å·¥å…·æ’ä»¶

è·å– Docker å®¹å™¨çš„èµ„æºä½¿ç”¨æƒ…å†µ
"""

from typing import Dict, Any
import docker

class DockerStatsTool(Tool):
    """Docker ç»Ÿè®¡å·¥å…·"""

    def __init__(self):
        self.client = docker.from_env()

        self.definition = ToolDefinition(
            name="docker_stats",
            description="Get Docker container resource usage",
            category=ToolCategory.SYSTEM,
            parameters={
                "container_id": {
                    "type": "string",
                    "description": "Container ID or name",
                    "required": False
                },
                "all": {
                    "type": "boolean",
                    "description": "Show all containers",
                    "required": False,
                    "default": False
                }
            },
            required_permissions=["docker:read"],
            timeout=10,
            cacheable=False
        )

    async def execute(
        self,
        arguments: Dict[str, Any],
        context: ExecutionContext
    ) -> Dict[str, Any]:
        """æ‰§è¡Œ Docker ç»Ÿè®¡"""
        container_id = arguments.get("container_id")
        show_all = arguments.get("all", False)

        if container_id:
            # è·å–å•ä¸ªå®¹å™¨ç»Ÿè®¡
            container = self.client.containers.get(container_id)
            stats = container.stats(stream=False)

            return {
                "container_id": container.id,
                "name": container.name,
                "cpu_percent": self._calculate_cpu_percent(stats),
                "memory_usage": stats["memory_stats"]["usage"],
                "memory_limit": stats["memory_stats"]["limit"],
                "network_rx": stats["networks"]["eth0"]["rx_bytes"],
                "network_tx": stats["networks"]["eth0"]["tx_bytes"]
            }
        else:
            # è·å–æ‰€æœ‰å®¹å™¨ç»Ÿè®¡
            containers = self.client.containers.list(all=show_all)
            results = []

            for container in containers:
                stats = container.stats(stream=False)
                results.append({
                    "container_id": container.id,
                    "name": container.name,
                    "status": container.status,
                    "cpu_percent": self._calculate_cpu_percent(stats),
                    "memory_usage": stats["memory_stats"]["usage"],
                    "memory_limit": stats["memory_stats"]["limit"]
                })

            return {
                "containers": results,
                "total": len(results)
            }

    def _calculate_cpu_percent(self, stats: Dict) -> float:
        """è®¡ç®— CPU ä½¿ç”¨ç‡"""
        cpu_delta = stats["cpu_stats"]["cpu_usage"]["total_usage"] - \
                    stats["precpu_stats"]["cpu_usage"]["total_usage"]
        system_delta = stats["cpu_stats"]["system_cpu_usage"] - \
                       stats["precpu_stats"]["system_cpu_usage"]

        if system_delta > 0:
            cpu_percent = (cpu_delta / system_delta) * 100.0
            return round(cpu_percent, 2)

        return 0.0
```

### æ’ä»¶é…ç½®

**plugins/config.yaml**:
```yaml
plugins:
  - name: docker_stats
    enabled: true
    permissions:
      - docker:read
    config:
      timeout: 10
      cache_ttl: 60

  - name: kubernetes_pods
    enabled: true
    permissions:
      - k8s:read
    config:
      kubeconfig: /path/to/kubeconfig
      namespace: default

  - name: database_query
    enabled: false
    permissions:
      - db:read
    config:
      connection_string: postgresql://localhost/db
      max_rows: 1000
```

---

## ğŸ”’ å®‰å…¨æœºåˆ¶

### 1. æƒé™ç³»ç»Ÿ

```python
class Permission(Enum):
    """æƒé™æšä¸¾"""
    READ_CODE = "read:code"
    READ_FILE = "read:file"
    WRITE_FILE = "write:file"
    EXECUTE_COMMAND = "execute:command"
    WEB_SEARCH = "web:search"
    DOCKER_READ = "docker:read"
    DOCKER_WRITE = "docker:write"
    GIT_READ = "read:git"
    GIT_WRITE = "write:git"

class PermissionManager:
    """æƒé™ç®¡ç†å™¨"""

    def __init__(self):
        self.role_permissions: Dict[str, List[Permission]] = {
            "readonly": [
                Permission.READ_CODE,
                Permission.READ_FILE,
                Permission.WEB_SEARCH
            ],
            "developer": [
                Permission.READ_CODE,
                Permission.READ_FILE,
                Permission.WRITE_FILE,
                Permission.GIT_READ,
                Permission.GIT_WRITE
            ],
            "admin": list(Permission)  # æ‰€æœ‰æƒé™
        }

    def check_permission(
        self,
        user_role: str,
        required_permission: Permission
    ) -> bool:
        """æ£€æŸ¥æƒé™"""
        if user_role not in self.role_permissions:
            return False

        return required_permission in self.role_permissions[user_role]

    def get_permissions(self, user_role: str) -> List[Permission]:
        """è·å–è§’è‰²çš„æ‰€æœ‰æƒé™"""
        return self.role_permissions.get(user_role, [])
```

### 2. å‚æ•°éªŒè¯

```python
class ParameterValidator:
    """å‚æ•°éªŒè¯å™¨"""

    @staticmethod
    def validate(
        parameters: Dict[str, Any],
        schema: Dict[str, Any]
    ) -> Tuple[bool, Optional[str]]:
        """éªŒè¯å‚æ•°"""
        # 1. æ£€æŸ¥å¿…éœ€å‚æ•°
        for param_name, param_schema in schema.items():
            if param_schema.get("required", False):
                if param_name not in parameters:
                    return False, f"Missing required parameter: {param_name}"

        # 2. éªŒè¯å‚æ•°ç±»å‹
        for param_name, param_value in parameters.items():
            if param_name not in schema:
                return False, f"Unknown parameter: {param_name}"

            param_schema = schema[param_name]
            expected_type = param_schema["type"]

            if not ParameterValidator._check_type(param_value, expected_type):
                return False, f"Invalid type for {param_name}: expected {expected_type}"

        # 3. éªŒè¯å‚æ•°èŒƒå›´
        for param_name, param_value in parameters.items():
            param_schema = schema[param_name]

            # æ•°å€¼èŒƒå›´
            if "min" in param_schema and param_value < param_schema["min"]:
                return False, f"{param_name} must be >= {param_schema['min']}"

            if "max" in param_schema and param_value > param_schema["max"]:
                return False, f"{param_name} must be <= {param_schema['max']}"

            # å­—ç¬¦ä¸²é•¿åº¦
            if "min_length" in param_schema and len(param_value) < param_schema["min_length"]:
                return False, f"{param_name} length must be >= {param_schema['min_length']}"

            if "max_length" in param_schema and len(param_value) > param_schema["max_length"]:
                return False, f"{param_name} length must be <= {param_schema['max_length']}"

            # æšä¸¾å€¼
            if "enum" in param_schema and param_value not in param_schema["enum"]:
                return False, f"{param_name} must be one of {param_schema['enum']}"

        return True, None

    @staticmethod
    def _check_type(value: Any, expected_type: str) -> bool:
        """æ£€æŸ¥ç±»å‹"""
        type_map = {
            "string": str,
            "integer": int,
            "number": (int, float),
            "boolean": bool,
            "array": list,
            "object": dict
        }

        expected = type_map.get(expected_type)
        if not expected:
            return False

        return isinstance(value, expected)
```

### 3. è·¯å¾„å®‰å…¨

```python
class PathValidator:
    """è·¯å¾„éªŒè¯å™¨"""

    @staticmethod
    def validate_path(
        path: str,
        workspace: str,
        allow_absolute: bool = False
    ) -> Tuple[bool, Optional[str]]:
        """éªŒè¯è·¯å¾„å®‰å…¨æ€§"""
        import os

        # 1. æ£€æŸ¥è·¯å¾„éå†æ”»å‡»
        if ".." in path:
            return False, "Path traversal detected"

        # 2. æ„å»ºå®Œæ•´è·¯å¾„
        if os.path.isabs(path):
            if not allow_absolute:
                return False, "Absolute paths not allowed"
            full_path = path
        else:
            full_path = os.path.join(workspace, path)

        # 3. è§„èŒƒåŒ–è·¯å¾„
        full_path = os.path.abspath(full_path)

        # 4. æ£€æŸ¥æ˜¯å¦åœ¨å·¥ä½œç©ºé—´å†…
        if not full_path.startswith(workspace):
            return False, "Path outside workspace"

        # 5. æ£€æŸ¥ç¬¦å·é“¾æ¥
        if os.path.islink(full_path):
            real_path = os.path.realpath(full_path)
            if not real_path.startswith(workspace):
                return False, "Symlink points outside workspace"

        return True, None

    @staticmethod
    def sanitize_filename(filename: str) -> str:
        """æ¸…ç†æ–‡ä»¶å"""
        import re

        # ç§»é™¤å±é™©å­—ç¬¦
        filename = re.sub(r'[^\w\s\-\.]', '', filename)

        # ç§»é™¤å¤šä½™çš„ç‚¹
        filename = re.sub(r'\.+', '.', filename)

        # é™åˆ¶é•¿åº¦
        if len(filename) > 255:
            filename = filename[:255]

        return filename
```

### 4. èµ„æºé™åˆ¶

```python
class ResourceLimiter:
    """èµ„æºé™åˆ¶å™¨"""

    def __init__(self):
        self.limits = {
            "max_execution_time": 300,  # 5 åˆ†é’Ÿ
            "max_memory": 1024 * 1024 * 1024,  # 1GB
            "max_cpu_percent": 50,
            "max_file_size": 100 * 1024 * 1024,  # 100MB
            "max_output_size": 10 * 1024 * 1024  # 10MB
        }

    def check_execution_time(self, start_time: float) -> bool:
        """æ£€æŸ¥æ‰§è¡Œæ—¶é—´"""
        elapsed = time.time() - start_time
        return elapsed < self.limits["max_execution_time"]

    def check_memory_usage(self, memory_bytes: int) -> bool:
        """æ£€æŸ¥å†…å­˜ä½¿ç”¨"""
        return memory_bytes < self.limits["max_memory"]

    def check_file_size(self, file_size: int) -> bool:
        """æ£€æŸ¥æ–‡ä»¶å¤§å°"""
        return file_size < self.limits["max_file_size"]

    def check_output_size(self, output_size: int) -> bool:
        """æ£€æŸ¥è¾“å‡ºå¤§å°"""
        return output_size < self.limits["max_output_size"]

    def truncate_output(self, output: str) -> str:
        """æˆªæ–­è¾“å‡º"""
        max_size = self.limits["max_output_size"]

        if len(output) <= max_size:
            return output

        truncated = output[:max_size]
        truncated += f"\n\n[Output truncated: {len(output)} bytes total]"

        return truncated
```

### 5. å®¡è®¡æ—¥å¿—

```python
class AuditLogger:
    """å®¡è®¡æ—¥å¿—"""

    def __init__(self, db: Database):
        self.db = db

    async def log_tool_execution(
        self,
        tool_name: str,
        arguments: Dict[str, Any],
        result: ToolResult,
        context: ExecutionContext
    ):
        """è®°å½•å·¥å…·æ‰§è¡Œ"""
        await self.db.execute(
            """
            INSERT INTO tool_audit_log (
                tool_name,
                user_id,
                workspace,
                arguments,
                success,
                duration_ms,
                error,
                created_at
            ) VALUES ($1, $2, $3, $4, $5, $6, $7, NOW())
            """,
            tool_name,
            context.user_id,
            context.workspace,
            json.dumps(arguments),
            result.success,
            result.duration_ms,
            result.error
        )

    async def log_permission_denied(
        self,
        tool_name: str,
        required_permission: str,
        context: ExecutionContext
    ):
        """è®°å½•æƒé™æ‹’ç»"""
        await self.db.execute(
            """
            INSERT INTO permission_denied_log (
                tool_name,
                user_id,
                required_permission,
                created_at
            ) VALUES ($1, $2, $3, NOW())
            """,
            tool_name,
            context.user_id,
            required_permission
        )

    async def get_user_activity(
        self,
        user_id: str,
        start_date: datetime,
        end_date: datetime
    ) -> List[Dict]:
        """è·å–ç”¨æˆ·æ´»åŠ¨"""
        rows = await self.db.fetch(
            """
            SELECT
                tool_name,
                COUNT(*) as call_count,
                AVG(duration_ms) as avg_duration,
                SUM(CASE WHEN success THEN 1 ELSE 0 END) as success_count
            FROM tool_audit_log
            WHERE user_id = $1
              AND created_at BETWEEN $2 AND $3
            GROUP BY tool_name
            ORDER BY call_count DESC
            """,
            user_id,
            start_date,
            end_date
        )

        return [dict(row) for row in rows]
```

---

## ğŸ“Š ç›‘æ§å’Œå¯è§‚æµ‹æ€§

### Prometheus æŒ‡æ ‡

```python
from prometheus_client import Counter, Histogram, Gauge

# å·¥å…·æ‰§è¡Œè®¡æ•°
tool_execution_count = Counter(
    'vlinders_tool_executions_total',
    'Total tool executions',
    ['tool_name', 'status']
)

# å·¥å…·æ‰§è¡Œæ—¶é—´
tool_execution_duration = Histogram(
    'vlinders_tool_execution_seconds',
    'Tool execution duration',
    ['tool_name'],
    buckets=[0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 30.0]
)

# å¹¶å‘å·¥å…·æ•°
concurrent_tools = Gauge(
    'vlinders_concurrent_tools',
    'Number of concurrent tool executions'
)

# æ²™ç®±å®¹å™¨æ•°
sandbox_containers = Gauge(
    'vlinders_sandbox_containers',
    'Number of active sandbox containers'
)

# ç¼“å­˜å‘½ä¸­ç‡
cache_hit_rate = Gauge(
    'vlinders_tool_cache_hit_rate',
    'Tool result cache hit rate',
    ['tool_name']
)
```

### OpenTelemetry è¿½è¸ª

```python
from opentelemetry import trace

tracer = trace.get_tracer(__name__)

async def execute_tool_with_tracing(
    tool: Tool,
    arguments: Dict[str, Any],
    context: ExecutionContext
) -> ToolResult:
    """å¸¦è¿½è¸ªçš„å·¥å…·æ‰§è¡Œ"""

    with tracer.start_as_current_span(
        "tool_execution",
        attributes={
            "tool.name": tool.name,
            "tool.category": tool.definition.category.value,
            "user.id": context.user_id,
            "workspace": context.workspace
        }
    ) as span:
        try:
            # æ‰§è¡Œå·¥å…·
            result = await tool.execute(arguments, context)

            span.set_attribute("tool.success", True)
            span.set_attribute("tool.cached", result.cached)

            return result

        except Exception as e:
            span.set_attribute("tool.success", False)
            span.set_attribute("tool.error", str(e))
            span.record_exception(e)
            raise
```

---

## ğŸ¯ å®Œæ•´å®ç°ç¤ºä¾‹

### ToolExecutor å®Œæ•´å®ç°

```python
"""
å·¥å…·æ‰§è¡Œå™¨ - å®Œæ•´å®ç°

è´Ÿè´£ç®¡ç†å’Œæ‰§è¡Œæ‰€æœ‰å·¥å…·
"""

import asyncio
import time
from typing import Dict, List, Any, Optional
from dataclasses import dataclass

class ToolExecutor:
    """å·¥å…·æ‰§è¡Œå™¨"""

    def __init__(
        self,
        registry: ToolRegistry,
        sandbox: Sandbox,
        cache: Cache,
        permission_manager: PermissionManager,
        audit_logger: AuditLogger,
        max_parallel: int = 10
    ):
        self.registry = registry
        self.sandbox = sandbox
        self.cache = cache
        self.permissions = permission_manager
        self.audit = audit_logger
        self.coordinator = ExecutionCoordinator(
            registry, sandbox, cache, max_parallel
        )
        self.dependency_analyzer = DependencyAnalyzer()
        self.concurrency_controller = ConcurrencyController(max_parallel)

    async def execute_batch(
        self,
        tool_calls: List[ToolCall],
        context: ExecutionContext
    ) -> List[ToolResult]:
        """
        æ‰¹é‡æ‰§è¡Œå·¥å…·

        æ”¯æŒ:
        - å¹¶è¡Œæ‰§è¡Œ
        - ä¾èµ–åˆ†æ
        - é”™è¯¯å¤„ç†
        - ç»“æœç¼“å­˜
        """
        if not tool_calls:
            return []

        # 1. åˆ†æä¾èµ–å…³ç³»
        groups = self.dependency_analyzer.analyze(tool_calls)

        # 2. æŒ‰ç»„æ‰§è¡Œ
        all_results = {}

        for group_calls in groups:
            # è·å–å½“å‰ç»„çš„å·¥å…·è°ƒç”¨
            calls = [
                call for call in tool_calls
                if call.id in group_calls
            ]

            # å¹¶è¡Œæ‰§è¡Œå½“å‰ç»„
            results = await self.concurrency_controller.execute_group(
                calls,
                self.coordinator,
                context
            )

            # ä¿å­˜ç»“æœ
            for call, result in zip(calls, results):
                all_results[call.id] = result

        # 3. æŒ‰åŸå§‹é¡ºåºè¿”å›ç»“æœ
        return [all_results[call.id] for call in tool_calls]

    async def execute_single(
        self,
        tool_call: ToolCall,
        context: ExecutionContext
    ) -> ToolResult:
        """æ‰§è¡Œå•ä¸ªå·¥å…·"""
        results = await self.execute_batch([tool_call], context)
        return results[0]

    async def list_available_tools(
        self,
        context: ExecutionContext
    ) -> List[ToolDefinition]:
        """åˆ—å‡ºå¯ç”¨å·¥å…·"""
        all_tools = self.registry.list_tools()

        # è¿‡æ»¤ç”¨æˆ·æœ‰æƒé™çš„å·¥å…·
        available_tools = []
        for tool_def in all_tools:
            if self._has_permissions(tool_def, context):
                available_tools.append(tool_def)

        return available_tools

    def _has_permissions(
        self,
        tool_def: ToolDefinition,
        context: ExecutionContext
    ) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰æƒé™"""
        for perm in tool_def.required_permissions:
            if perm not in context.permissions:
                return False
        return True
```

---

## ğŸ“ æ€»ç»“

Vlinders-Server çš„å·¥å…·æ‰§è¡Œå¼•æ“è®¾è®¡éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š

1. **å®‰å…¨ç¬¬ä¸€** - Docker æ²™ç®±éš”ç¦»ï¼Œå®Œå–„çš„æƒé™ç³»ç»Ÿ
2. **é«˜æ€§èƒ½** - å¹¶è¡Œæ‰§è¡Œï¼Œæ™ºèƒ½ç¼“å­˜
3. **å¯æ‰©å±•** - æ’ä»¶ç³»ç»Ÿï¼Œæ˜“äºæ·»åŠ æ–°å·¥å…·
4. **å¯è§‚æµ‹** - å®Œæ•´çš„æ—¥å¿—å’Œç›‘æ§
5. **å®¹é”™æ€§** - ä¼˜é›…å¤„ç†é”™è¯¯ï¼Œè¶…æ—¶æ§åˆ¶

### æ ¸å¿ƒç‰¹æ€§

- âœ… 5 ä¸ªå†…ç½®å·¥å…·ï¼ˆä»£ç æœç´¢ã€è¯­ä¹‰æœç´¢ã€æ–‡ä»¶è¯»å–ã€ä»£ç åˆ†æã€Web æœç´¢ï¼‰
- âœ… Docker æ²™ç®±éš”ç¦»
- âœ… å¹¶è¡Œæ‰§è¡Œå’Œä¾èµ–åˆ†æ
- âœ… æ’ä»¶ç³»ç»Ÿ
- âœ… æƒé™ç®¡ç†
- âœ… ç»“æœç¼“å­˜
- âœ… å®¡è®¡æ—¥å¿—
- âœ… ç›‘æ§æŒ‡æ ‡

---

**ä¸‹ä¸€æ­¥**: é˜…è¯» [06-ä¸Šä¸‹æ–‡ç®¡ç†.md](./06-ä¸Šä¸‹æ–‡ç®¡ç†.md)
